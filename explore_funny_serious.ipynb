{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Funny vs. Serious Single Sentence Explorer\n\n**Research question:** Does an LLM represent \"funny\" and \"serious\" sentence endings differently, even when both sentences are grammatically valid and make sense?\n\n## Dataset\n\nWe use the **funny_serious_150** dataset: 75 pairs of completed sentences where each pair has:\n- A **serious** version: `\"The dangerous iPhone was arrested and charged with assault.\"`\n- A **funny** version: `\"The dangerous iPhone was arrested and charged with battery.\"`\n\nBoth versions are valid English sentences. The only difference is the final word — one has the \"pun\" word, one has a straightforward word.\n\n## Method\n\nWe collect activations from Llama-3.1-70B-Instruct at the **final period** of each sentence, then analyze whether the model's internal representation differs based on whether it just processed a funny or serious completion.\n\n## Contents\n1. Load data and extract group labels\n2. Compute separation metrics (Fisher, Cohen's d)  \n3. Visualizations\n4. Cross-validation to check for overfitting"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport json\nimport numpy as np\nfrom IPython.display import HTML, display\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Data loading\nfrom analyze_activations import load_activations, get_pair_indices\n\n# Explicit-argument analysis functions (show exactly what data is needed)\nfrom analyze_activations import (\n    mean_difference,           # (X, is_group_a, is_group_b) → direction\n    compute_fisher_separation, # (X, is_group_a, is_group_b) → float\n    compute_cohens_d,          # (X, is_group_a, is_group_b, direction) → float\n)\n\n# For visualization\nfrom analyze_activations import contrastive_projection, holdout_analysis\nfrom puns_viz import make_layer_viz"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Paths\nRAW_DIR = Path(\"results/raw_activations\")\nDATASET_FILE = Path(\"datasets/funny_serious_150.json\")\nMETA_FILE = RAW_DIR / \"llama31_70b_instruct_funnyserious150_pred_c_meta.json\"\n\n# Load activations: returns metadata, per-layer activations, and layer indices\nmeta, layer_data, layer_indices = load_activations(META_FILE)\n\n# Extract the key arrays we need for analysis:\n#   pair_ids:    which pair each prompt belongs to (0-74)\n#   is_funny:    True for prompts with the pun completion  \n#   is_serious:  True for prompts with the serious completion\npair_ids, is_funny, is_serious = get_pair_indices(meta)\n\nprint(f\"Model: {meta['model']}\")\nprint(f\"Layers: {len(layer_indices)} (indices 0-{layer_indices[-1]})\")\nprint(f\"Hidden dimension: {meta['hidden_dim']}\")\nprint(f\"Total prompts: {len(is_funny)}\")\nprint(f\"  - Funny completions: {is_funny.sum()}\")\nprint(f\"  - Serious completions: {is_serious.sum()}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "---\n## 1. Separation Metrics Across Layers\n\nWe'll compute two metrics at each layer:\n\n**Fisher separation** = (distance between group means) / (average within-group spread)\n- Measures how well-separated the two groups are in the full high-dimensional space\n- Higher = better separation\n\n**Cohen's d** = (mean_funny - mean_serious) / pooled_std, along the \"contrastive direction\"\n- The contrastive direction is simply: mean(funny) - mean(serious), normalized\n- Cohen's d tells us the effect size along this optimal separating direction\n- Interpretation: 0.2 = small, 0.5 = medium, 0.8 = large, >1.0 = very large"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# Compute metrics at each layer\nfisher_scores = []\ncohens_d_scores = []\n\nfor layer_idx in layer_indices:\n    # Get activations for this layer: shape (150, 8192)\n    X = layer_data[layer_idx]\n    \n    # Fisher separation: uses the full activation vectors\n    fisher = compute_fisher_separation(X, is_funny, is_serious)\n    fisher_scores.append(fisher)\n    \n    # Contrastive direction: the normalized mean difference\n    direction = mean_difference(X, is_funny, is_serious)\n    \n    # Cohen's d: effect size along the contrastive direction\n    d = compute_cohens_d(X, is_funny, is_serious, direction)\n    cohens_d_scores.append(d)\n\n# Find peak layers\npeak_fisher_idx = np.argmax(fisher_scores)\npeak_cd_idx = np.argmax(cohens_d_scores)\n\nprint(f\"Fisher separation peaks at layer {layer_indices[peak_fisher_idx]}: {fisher_scores[peak_fisher_idx]:.3f}\")\nprint(f\"Cohen's d peaks at layer {layer_indices[peak_cd_idx]}: {cohens_d_scores[peak_cd_idx]:.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Plot both metrics across layers\nfig, ax1 = plt.subplots(figsize=(12, 4))\n\nax1.plot(layer_indices, fisher_scores, color='#E85D75', lw=2, label='Fisher separation')\nax1.set_xlabel('Layer', fontsize=11)\nax1.set_ylabel('Fisher separation', fontsize=11, color='#E85D75')\nax1.tick_params(axis='y', labelcolor='#E85D75')\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\nax2 = ax1.twinx()\nax2.plot(layer_indices, cohens_d_scores, color='#2EAD6B', lw=2, ls='--', label=\"Cohen's d\")\nax2.set_ylabel(\"Cohen's d\", fontsize=11, color='#2EAD6B')\nax2.tick_params(axis='y', labelcolor='#2EAD6B')\nax2.spines['top'].set_visible(False)\n\nlines1, labels1 = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines1 + lines2, labels1 + labels2, fontsize=9, loc='upper left')\nax1.set_title('Funny vs. Serious: Separation by Layer', fontsize=13, fontweight='bold')\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "---\n## 2. Visualizations at Peak Layer\n\nLet's look at the actual activations at the layer with highest Cohen's d.\n\nThe \"contrastive projection\" shows:\n- **X-axis**: Projection onto the contrastive direction (mean_funny - mean_serious)\n- **Y-axis**: First principal component of the residual (what's left after removing the contrastive direction)\n\nLines connect each pair (funny and serious versions of the same joke)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# Get activations at peak Cohen's d layer\npeak_layer = layer_indices[peak_cd_idx]\nX_peak = layer_data[peak_layer]\n\n# Compute 2D contrastive projection (uses meta internally for pair structure)\nX_proj, components, var_ratios = contrastive_projection(X_peak, meta, n_components=2)\n\n# Plot\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Draw lines connecting each pair\nfor pid in sorted(set(pair_ids)):\n    mask = pair_ids == pid\n    if mask.sum() == 2:\n        pts = X_proj[mask]\n        ax.plot(pts[:, 0], pts[:, 1], color='#888', alpha=0.4, lw=0.8, zorder=1)\n\n# Scatter points\nax.scatter(X_proj[is_serious, 0], X_proj[is_serious, 1], c='#4A90D9', \n           s=40, alpha=0.7, label='Serious', edgecolors='white', lw=0.5, zorder=2)\nax.scatter(X_proj[is_funny, 0], X_proj[is_funny, 1], c='#E85D75',\n           s=40, alpha=0.7, label='Funny', edgecolors='white', lw=0.5, zorder=2)\n\nax.set_xlabel(f'Contrastive direction ({var_ratios[0]:.1%} variance)', fontsize=11)\nax.set_ylabel(f'Residual PC1 ({var_ratios[1]:.1%} variance)', fontsize=11)\nax.set_title(f'Layer {peak_layer}: Contrastive Projection (Cohen\\'s d = {cohens_d_scores[peak_cd_idx]:.2f})', \n             fontsize=13, fontweight='bold')\nax.legend(fontsize=10)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# 1D histogram: projection onto contrastive direction\ndirection = mean_difference(X_peak, is_funny, is_serious)\nprojections = X_peak @ direction\n\nfig, ax = plt.subplots(figsize=(10, 4))\nax.hist(projections[is_serious], bins=15, alpha=0.6, color='#4A90D9', label='Serious', edgecolor='white')\nax.hist(projections[is_funny], bins=15, alpha=0.6, color='#E85D75', label='Funny', edgecolor='white')\nax.set_xlabel('Projection onto contrastive direction', fontsize=11)\nax.set_ylabel('Count', fontsize=11)\nax.set_title(f'Layer {peak_layer}: 1D Projections (Cohen\\'s d = {cohens_d_scores[peak_cd_idx]:.2f})',\n             fontsize=13, fontweight='bold')\nax.legend(fontsize=10)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Interactive 3D Layer Explorer\n",
    "\n",
    "- **Drag** to rotate\n",
    "- **Scroll/pinch** to zoom\n",
    "- **Shift-drag** to pan\n",
    "- **Layer slider** to move through all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# Note: pred_file=False skips loading predictions because pun boost isn't meaningful\n# for this dataset - these are completed sentences, not cloze predictions.\nhtml = make_layer_viz(META_FILE, pred_file=False, width=900, height=600)\nHTML(html)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": "---\n## 4. Cross-Validation: Are We Overfitting?\n\nThe contrastive direction is computed from the same data we use to measure Cohen's d. This could overfit — we might find a direction that separates *these specific* prompts but wouldn't generalize.\n\n**Holdout analysis**: Split pairs into two groups, compute the contrastive direction from one group, measure Cohen's d on the other. If the cross-validated Cohen's d is close to the full-data Cohen's d, the separation is real (not overfit)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# Run holdout analysis (splits pairs, trains direction on half, tests on other half)\nholdout = holdout_analysis(layer_data, meta, n_splits=2, seed=42)\n\nfig, ax = plt.subplots(figsize=(12, 4))\nax.plot(holdout['layer_indices'], holdout['cohens_d_full'], color='#2EAD6B', lw=2, label='Full data')\nax.plot(holdout['layer_indices'], holdout['cohens_d_cv'], color='#E85D75', lw=2, ls='--', label='Cross-validated')\nax.set_xlabel('Layer', fontsize=11)\nax.set_ylabel(\"Cohen's d\", fontsize=11)\nax.set_title(\"Full Data vs. Cross-Validated Cohen's d\", fontsize=13, fontweight='bold')\nax.legend(fontsize=10)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nfig.tight_layout()\nplt.show()\n\n# Report the gap at peak layer\ncv_at_peak = holdout['cohens_d_cv'][peak_cd_idx]\nfull_at_peak = holdout['cohens_d_full'][peak_cd_idx]\nprint(f\"\\nAt peak layer {peak_layer}:\")\nprint(f\"  Full-data Cohen's d: {full_at_peak:.2f}\")\nprint(f\"  Cross-validated:     {cv_at_peak:.2f}\")\nprint(f\"  Ratio (CV/full):     {cv_at_peak/full_at_peak:.1%}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Sample Prompts\n",
    "\n",
    "View some example prompt pairs to understand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample prompt pairs:\n",
      "\n",
      "Pair 0:\n",
      "  Serious: \"The dangerous iPhone was arrested and charged with assault.\"\n",
      "  Funny:   \"The dangerous iPhone was arrested and charged with battery.\"\n",
      "\n",
      "Pair 1:\n",
      "  Serious: \"The bread was afraid to be best man, because he would have to make a speech.\"\n",
      "  Funny:   \"The bread was afraid to be best man, because he would have to make a toast.\"\n",
      "\n",
      "Pair 2:\n",
      "  Serious: \"The wizard ran a fantastic music school because he had a great passion.\"\n",
      "  Funny:   \"The wizard ran a fantastic music school because he had a great staff.\"\n",
      "\n",
      "Pair 3:\n",
      "  Serious: \"The mushroom's salary never went up because there was always a ceiling.\"\n",
      "  Funny:   \"The mushroom's salary never went up because there was always a cap.\"\n",
      "\n",
      "Pair 4:\n",
      "  Serious: \"The vulture boarded the airplane with two dead raccoons but was told he was only allowed one carry-on.\"\n",
      "  Funny:   \"The vulture boarded the airplane with two dead raccoons but was told he was only allowed one carrion.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(DATASET_FILE) as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "print(\"Sample prompt pairs:\\n\")\n",
    "for i in range(0, min(10, len(dataset)), 2):\n",
    "    serious = dataset[i]\n",
    "    funny = dataset[i+1]\n",
    "    print(f\"Pair {serious['pair_id']}:\")\n",
    "    print(f\"  Serious: \\\"{serious['prompt']}\\\"\")\n",
    "    print(f\"  Funny:   \\\"{funny['prompt']}\\\"\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Puns (3.12)",
   "language": "python",
   "name": "puns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}